#  ヒントとか

LoRAを数百個作った経験に基づく主観的な内容なので参考程度に。

## 次元数(DimまたはRank)は高いほうがいいの？

高いほど学習能力が上昇するが学習・生成が遅くなる。また高くしても細かい部分が良くなったりはしない。高いほど生成時に崩壊しやすい。

キャラは64、画風は16以下でいい。

## アルファのおすすめの値は？

dimの半分以下。高いほど生成時に崩壊しやすくなる。低すぎると学習能力が若干低下する。

## mean ar errorってなに？

画像リサイズ時のアスペクト比の誤差。0-1の範囲で示される。プログラムのエラーではない。

## データローダーのCPUスレッド数を上げると速くなる？

学習がシングルスレッド性能に強く依存してるためかほとんど変わらない。

メモリ消費が増えるだけっぽい。2でいい。

## Optimizerはどれがいい？

AdamWが無難。特別高性能ではないが、癖がなく失敗が少ない。再現度が欲しいならDAdaptLionがおすすめ。これも癖が少なめでいい。

Prodigyは学習結果に癖があるように感じる。

AdaFactorはLoRA学習で特にメリットはない。

## キャプショニングはどうする？

https://rentry.co/irir_lora#%E3%82%BF%E3%82%B0%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6

## おすすめのステップ数？

キャラが3000-6000、画風が5000-10000、構図,シチュエーション,ポーズは9000以上。